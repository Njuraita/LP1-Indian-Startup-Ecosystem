{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CA-7 LP1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bussiness Understanding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our team is intending to venture into the Indian Ecosyatem and as data analyst we are to investigate the ecosystem and propose best course of action.\n",
    "\n",
    "We will be using the CRISP-DM Methodology. We are to understand the objectives and requirements of the project, determine data mining goals, define business success criteria. Detailed plan for each project phase \n",
    "\n",
    "\n",
    "### Project Title : Viability of Setting up a Startup Business in India \n",
    "\n",
    " * Hypothesis testing:\n",
    "\n",
    " Null Hypothesis (H0) There is no significant difference in the amount of funding recieved by startups across different sectors and stages \n",
    "\n",
    " Alternative Hypothesis (H1) There is a significant difference in the amount of funding recieved by different sectors and stages \n",
    " \n",
    "\n",
    "* Project Description - \n",
    "Our team is aiming at setting up startup in India. Using the provided information we are accessing the viability of setting up our busiess there .\n",
    "\n",
    "\n",
    "\n",
    "ANALYTICAL QUESTIONS\n",
    "1. Funding Trends:\n",
    "How has the total funding amount changed year over year from 2018 to 2021?\n",
    "How has the average funding amount in each sector changed over the years (2018 - 2021)\n",
    " \n",
    "2. Sector Analysis:\n",
    "Which sectors have received the most funding, and how does the funding distribution vary across sectors?\n",
    " \n",
    "3. Stage Analysis:\n",
    "What is the distribution of funding across different investment stages (e.g., Pre-seed, Seed, Series A)?\n",
    " \n",
    "4. Geographical Analysis:\n",
    "Which cities or regions have the highest concentration of funded startups?\n",
    " \n",
    "5. Investor Influence:\n",
    "Who are the top investors in the Indian startup ecosystem, and what is their funding pattern?\n",
    " \n",
    "6. Founder Impact:\n",
    "Is there a correlation between the number of founders and the amount of funding received?\n",
    " \n",
    "7. What are the characteristics of startups in the highest-funded sectors (e.g., number of founders, location)?\n",
    " \n",
    "8. Which Business is more viable to set - The best performing business(s) ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We have been provided with various datasets located at 3 different locations ie Database, OneDrive and GitHub Repository. In them we will find the start-ups details, the funding amounts recieved and the investors information from 2018-2021.\n",
    " To provide a smooth flow of project, in this phase we will be loading the data and cleaning the data. In the next phase, data preparation phase, we will then concatenate the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: '#install'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: openpyxl in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.1.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openpyxl) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "#Install necessary libraries \n",
    "\n",
    "%pip install pyodbc #install our connector which allows us to connect with our databases\n",
    "%pip install python-dotenv\n",
    "%pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the necessary packages \n",
    "\n",
    "import pyodbc \n",
    "from dotenv import dotenv_values \n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "import pandas as pd \n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings ('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file into a dictionary\n",
    "environment_variables = dotenv_values('C:\\\\Users\\\\Admin\\\\OneDrive\\\\OneDrive-Azubi\\\\CA-LP1\\\\LP1-Indian-Startup-Ecosystem-1\\\\Notebooks\\\\.env')\n",
    "\n",
    "# Get the values for the credentials you set in the '.env' file\n",
    "server = environment_variables.get('server')\n",
    "database = environment_variables.get('database')\n",
    "username = environment_variables.get('username')\n",
    "password = environment_variables.get('password')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a connection string\n",
    "\n",
    "connection_string = f\"DRIVER={{SQL Server}};SERVER={server};DATABASE={database};UID={username};PWD={password};MARS_Connection=yes;MinProtocolVersion=TLSv1.2;\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = pyodbc.connect(connection_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1st Dataset-2020 (Data)\n",
    "\n",
    "* This dataset is loaded from SQL Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the tabeles as per the given instructions (1st Dataset)\n",
    "\n",
    "query = '''SELECT *\n",
    "FROM dbo.LP1_startup_funding2020'''\n",
    "\n",
    "data =pd.read_sql(query, connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Brand</th>\n",
       "      <th>Founded</th>\n",
       "      <th>HeadQuarter</th>\n",
       "      <th>Sector</th>\n",
       "      <th>What_it_does</th>\n",
       "      <th>Founders</th>\n",
       "      <th>Investor</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Stage</th>\n",
       "      <th>column10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aqgromalin</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>AgriTech</td>\n",
       "      <td>Cultivating Ideas for Profit</td>\n",
       "      <td>Prasanna Manogaran, Bharani C L</td>\n",
       "      <td>Angel investors</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Krayonnz</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>EdTech</td>\n",
       "      <td>An academy-guardian-scholar centric ecosystem ...</td>\n",
       "      <td>Saurabh Dixit, Gurudutt Upadhyay</td>\n",
       "      <td>GSF Accelerator</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>Pre-seed</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PadCare Labs</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Hygiene management</td>\n",
       "      <td>Converting bio-hazardous waste to harmless waste</td>\n",
       "      <td>Ajinkya Dhariya</td>\n",
       "      <td>Venture Center</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pre-seed</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NCOME</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Escrow</td>\n",
       "      <td>Escrow-as-a-service platform</td>\n",
       "      <td>Ritesh Tiwari</td>\n",
       "      <td>Venture Catalysts, PointOne Capital</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gramophone</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>Indore</td>\n",
       "      <td>AgriTech</td>\n",
       "      <td>Gramophone is an AgTech platform enabling acce...</td>\n",
       "      <td>Ashish Rajan Singh, Harshit Gupta, Nishant Mah...</td>\n",
       "      <td>Siana Capital Management, Info Edge</td>\n",
       "      <td>340000.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>qZense</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>AgriTech</td>\n",
       "      <td>qZense Labs is building the next-generation Io...</td>\n",
       "      <td>Rubal Chib, Dr Srishti Batra</td>\n",
       "      <td>Venture Catalysts, 9Unicorns Accelerator Fund</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>Seed</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MyClassboard</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>EdTech</td>\n",
       "      <td>MyClassboard is a full-fledged School / Colleg...</td>\n",
       "      <td>Ajay Sakhamuri</td>\n",
       "      <td>ICICI Bank.</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>Pre-series A</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Metvy</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Networking platform</td>\n",
       "      <td>AI driven networking platform for individuals ...</td>\n",
       "      <td>Shawrya Mehrotra</td>\n",
       "      <td>HostelFund</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pre-series</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Rupeek</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>FinTech</td>\n",
       "      <td>Rupeek is an online lending platform that spec...</td>\n",
       "      <td>Amar Prabhu, Ashwin Soni, Sumit Maniyar</td>\n",
       "      <td>KB Investment, Bertelsmann India Investments</td>\n",
       "      <td>45000000.0</td>\n",
       "      <td>Series C</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Gig India</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Crowdsourcing</td>\n",
       "      <td>GigIndia is a marketplace that provides on-dem...</td>\n",
       "      <td>Aditya Shirole, Sahil Sharma</td>\n",
       "      <td>Shantanu Deshpande, Subramaniam Ramadorai</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>Pre-series A</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Company_Brand  Founded HeadQuarter               Sector  \\\n",
       "0    Aqgromalin   2019.0     Chennai             AgriTech   \n",
       "1      Krayonnz   2019.0   Bangalore               EdTech   \n",
       "2  PadCare Labs   2018.0        Pune   Hygiene management   \n",
       "3         NCOME   2020.0   New Delhi               Escrow   \n",
       "4    Gramophone   2016.0      Indore             AgriTech   \n",
       "5        qZense   2019.0   Bangalore             AgriTech   \n",
       "6  MyClassboard   2008.0   Hyderabad               EdTech   \n",
       "7         Metvy   2018.0     Gurgaon  Networking platform   \n",
       "8        Rupeek   2015.0   Bangalore              FinTech   \n",
       "9     Gig India   2017.0        Pune        Crowdsourcing   \n",
       "\n",
       "                                        What_it_does  \\\n",
       "0                       Cultivating Ideas for Profit   \n",
       "1  An academy-guardian-scholar centric ecosystem ...   \n",
       "2   Converting bio-hazardous waste to harmless waste   \n",
       "3                       Escrow-as-a-service platform   \n",
       "4  Gramophone is an AgTech platform enabling acce...   \n",
       "5  qZense Labs is building the next-generation Io...   \n",
       "6  MyClassboard is a full-fledged School / Colleg...   \n",
       "7  AI driven networking platform for individuals ...   \n",
       "8  Rupeek is an online lending platform that spec...   \n",
       "9  GigIndia is a marketplace that provides on-dem...   \n",
       "\n",
       "                                            Founders  \\\n",
       "0                    Prasanna Manogaran, Bharani C L   \n",
       "1                   Saurabh Dixit, Gurudutt Upadhyay   \n",
       "2                                    Ajinkya Dhariya   \n",
       "3                                      Ritesh Tiwari   \n",
       "4  Ashish Rajan Singh, Harshit Gupta, Nishant Mah...   \n",
       "5                       Rubal Chib, Dr Srishti Batra   \n",
       "6                                     Ajay Sakhamuri   \n",
       "7                                   Shawrya Mehrotra   \n",
       "8            Amar Prabhu, Ashwin Soni, Sumit Maniyar   \n",
       "9                       Aditya Shirole, Sahil Sharma   \n",
       "\n",
       "                                        Investor      Amount         Stage  \\\n",
       "0                                Angel investors    200000.0          None   \n",
       "1                                GSF Accelerator    100000.0      Pre-seed   \n",
       "2                                 Venture Center         NaN      Pre-seed   \n",
       "3            Venture Catalysts, PointOne Capital    400000.0          None   \n",
       "4            Siana Capital Management, Info Edge    340000.0          None   \n",
       "5  Venture Catalysts, 9Unicorns Accelerator Fund    600000.0          Seed   \n",
       "6                                    ICICI Bank.    600000.0  Pre-series A   \n",
       "7                                     HostelFund         NaN    Pre-series   \n",
       "8   KB Investment, Bertelsmann India Investments  45000000.0      Series C   \n",
       "9      Shantanu Deshpande, Subramaniam Ramadorai   1000000.0  Pre-series A   \n",
       "\n",
       "  column10  \n",
       "0     None  \n",
       "1     None  \n",
       "2     None  \n",
       "3     None  \n",
       "4     None  \n",
       "5     None  \n",
       "6     None  \n",
       "7     None  \n",
       "8     None  \n",
       "9     None  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head (10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Brand</th>\n",
       "      <th>Founded</th>\n",
       "      <th>HeadQuarter</th>\n",
       "      <th>Sector</th>\n",
       "      <th>What_it_does</th>\n",
       "      <th>Founders</th>\n",
       "      <th>Investor</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Stage</th>\n",
       "      <th>column10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>XpressBees</td>\n",
       "      <td>2015</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Logistics</td>\n",
       "      <td>Provides end to end supply chain solutions</td>\n",
       "      <td>Supam Maheshwari, Amitava Saha</td>\n",
       "      <td>Alibaba</td>\n",
       "      <td>10000000.0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046</th>\n",
       "      <td>FarmERP</td>\n",
       "      <td>2001</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Agritech</td>\n",
       "      <td>Smart agriculture management ERP software plat...</td>\n",
       "      <td>Santosh Shinde, Sanjay Borkar</td>\n",
       "      <td>TechnoGen</td>\n",
       "      <td>3000000.0</td>\n",
       "      <td>Series A</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047</th>\n",
       "      <td>Wealth Bucket</td>\n",
       "      <td>2018</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Fintech</td>\n",
       "      <td>An online platform for mutual fund investments</td>\n",
       "      <td>Himanshu Jain, Pulkit Jain</td>\n",
       "      <td>NorthStar, Vinod Khatumal</td>\n",
       "      <td>3000000.0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048</th>\n",
       "      <td>GoMechanic</td>\n",
       "      <td>2016</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Automobile Technology</td>\n",
       "      <td>Find automobile repair and maintenance service...</td>\n",
       "      <td>Amit Bhasin, Kushal Karwa, Nitin Rana, Rishabh...</td>\n",
       "      <td>Chiratae Ventures, Sequoia Capital, Orios Vent...</td>\n",
       "      <td>14700000.0</td>\n",
       "      <td>Series B</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>Fashor</td>\n",
       "      <td>2017</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Fashion</td>\n",
       "      <td>Women’s fashion and apparel</td>\n",
       "      <td>Vikram Kankaria, Priyanka Kankaria</td>\n",
       "      <td>Sprout venture partners</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>Pre Series A</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>Leverage Edu</td>\n",
       "      <td>0</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Edtech</td>\n",
       "      <td>AI enabled marketplace that provides career gu...</td>\n",
       "      <td>Akshay Chaturvedi</td>\n",
       "      <td>DSG Consumer Partners, Blume Ventures</td>\n",
       "      <td>1500000.0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051</th>\n",
       "      <td>EpiFi</td>\n",
       "      <td>0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Fintech</td>\n",
       "      <td>It offers customers with a single interface fo...</td>\n",
       "      <td>Sujith Narayanan, Sumit Gwalani</td>\n",
       "      <td>Sequoia India, Ribbit Capital</td>\n",
       "      <td>13200000.0</td>\n",
       "      <td>Seed Round</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052</th>\n",
       "      <td>Purplle</td>\n",
       "      <td>2012</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Cosmetics</td>\n",
       "      <td>Online makeup and beauty products retailer</td>\n",
       "      <td>Manish Taneja, Rahul Dash</td>\n",
       "      <td>Verlinvest</td>\n",
       "      <td>8000000.0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>Shuttl</td>\n",
       "      <td>2015</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Transport</td>\n",
       "      <td>App based bus aggregator serice</td>\n",
       "      <td>Amit Singh, Deepanshu Malviya</td>\n",
       "      <td>SIG Global India Fund LLP.</td>\n",
       "      <td>8043000.0</td>\n",
       "      <td>Series C</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>Pando</td>\n",
       "      <td>2017</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Logitech</td>\n",
       "      <td>Networked logistics management software</td>\n",
       "      <td>Jayakrishnan, Abhijeet Manohar</td>\n",
       "      <td>Chiratae Ventures</td>\n",
       "      <td>9000000.0</td>\n",
       "      <td>Series A</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Company_Brand  Founded HeadQuarter                 Sector  \\\n",
       "1045     XpressBees     2015     Unknown              Logistics   \n",
       "1046        FarmERP     2001        Pune               Agritech   \n",
       "1047  Wealth Bucket     2018     Unknown                Fintech   \n",
       "1048     GoMechanic     2016       Delhi  Automobile Technology   \n",
       "1049         Fashor     2017     Chennai                Fashion   \n",
       "1050   Leverage Edu        0       Delhi                 Edtech   \n",
       "1051          EpiFi        0     Unknown                Fintech   \n",
       "1052        Purplle     2012      Mumbai              Cosmetics   \n",
       "1053         Shuttl     2015       Delhi              Transport   \n",
       "1054          Pando     2017     Chennai               Logitech   \n",
       "\n",
       "                                           What_it_does  \\\n",
       "1045         Provides end to end supply chain solutions   \n",
       "1046  Smart agriculture management ERP software plat...   \n",
       "1047     An online platform for mutual fund investments   \n",
       "1048  Find automobile repair and maintenance service...   \n",
       "1049                        Women’s fashion and apparel   \n",
       "1050  AI enabled marketplace that provides career gu...   \n",
       "1051  It offers customers with a single interface fo...   \n",
       "1052         Online makeup and beauty products retailer   \n",
       "1053                    App based bus aggregator serice   \n",
       "1054            Networked logistics management software   \n",
       "\n",
       "                                               Founders  \\\n",
       "1045                     Supam Maheshwari, Amitava Saha   \n",
       "1046                      Santosh Shinde, Sanjay Borkar   \n",
       "1047                         Himanshu Jain, Pulkit Jain   \n",
       "1048  Amit Bhasin, Kushal Karwa, Nitin Rana, Rishabh...   \n",
       "1049                 Vikram Kankaria, Priyanka Kankaria   \n",
       "1050                                  Akshay Chaturvedi   \n",
       "1051                    Sujith Narayanan, Sumit Gwalani   \n",
       "1052                          Manish Taneja, Rahul Dash   \n",
       "1053                      Amit Singh, Deepanshu Malviya   \n",
       "1054                     Jayakrishnan, Abhijeet Manohar   \n",
       "\n",
       "                                               Investor      Amount  \\\n",
       "1045                                            Alibaba  10000000.0   \n",
       "1046                                          TechnoGen   3000000.0   \n",
       "1047                          NorthStar, Vinod Khatumal   3000000.0   \n",
       "1048  Chiratae Ventures, Sequoia Capital, Orios Vent...  14700000.0   \n",
       "1049                            Sprout venture partners   1000000.0   \n",
       "1050              DSG Consumer Partners, Blume Ventures   1500000.0   \n",
       "1051                      Sequoia India, Ribbit Capital  13200000.0   \n",
       "1052                                         Verlinvest   8000000.0   \n",
       "1053                         SIG Global India Fund LLP.   8043000.0   \n",
       "1054                                  Chiratae Ventures   9000000.0   \n",
       "\n",
       "             Stage column10  \n",
       "1045       Unknown     None  \n",
       "1046      Series A     None  \n",
       "1047       Unknown     None  \n",
       "1048      Series B     None  \n",
       "1049  Pre Series A     None  \n",
       "1050       Unknown     None  \n",
       "1051    Seed Round     None  \n",
       "1052       Unknown     None  \n",
       "1053      Series C     None  \n",
       "1054      Series A     None  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1055 entries, 0 to 1054\n",
      "Data columns (total 10 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Company_Brand  1055 non-null   object \n",
      " 1   Founded        842 non-null    float64\n",
      " 2   HeadQuarter    961 non-null    object \n",
      " 3   Sector         1042 non-null   object \n",
      " 4   What_it_does   1055 non-null   object \n",
      " 5   Founders       1043 non-null   object \n",
      " 6   Investor       1017 non-null   object \n",
      " 7   Amount         801 non-null    float64\n",
      " 8   Stage          591 non-null    object \n",
      " 9   column10       2 non-null      object \n",
      "dtypes: float64(2), object(8)\n",
      "memory usage: 82.5+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Company_Brand', 'Founded', 'HeadQuarter', 'Sector', 'What_it_does',\n",
       "       'Founders', 'Investor', 'Amount', 'Stage', 'column10'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Company_Brand       0\n",
       "Founded           213\n",
       "HeadQuarter        94\n",
       "Sector             13\n",
       "What_it_does        0\n",
       "Founders           12\n",
       "Investor           38\n",
       "Amount            254\n",
       "Stage             464\n",
       "column10         1053\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1055, 10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Founded</th>\n",
       "      <td>842.0</td>\n",
       "      <td>2.015363e+03</td>\n",
       "      <td>4.097909e+00</td>\n",
       "      <td>1973.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>2.020000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amount</th>\n",
       "      <td>801.0</td>\n",
       "      <td>1.130430e+08</td>\n",
       "      <td>2.476635e+09</td>\n",
       "      <td>12700.0</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>3000000.0</td>\n",
       "      <td>11000000.0</td>\n",
       "      <td>7.000000e+10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count          mean           std      min        25%        50%  \\\n",
       "Founded  842.0  2.015363e+03  4.097909e+00   1973.0     2014.0     2016.0   \n",
       "Amount   801.0  1.130430e+08  2.476635e+09  12700.0  1000000.0  3000000.0   \n",
       "\n",
       "                75%           max  \n",
       "Founded      2018.0  2.020000e+03  \n",
       "Amount   11000000.0  7.000000e+10  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Company_Brand    905\n",
       "Founded           26\n",
       "HeadQuarter       77\n",
       "Sector           302\n",
       "What_it_does     990\n",
       "Founders         927\n",
       "Investor         848\n",
       "Amount           300\n",
       "Stage             42\n",
       "column10           2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Company_Brand', 'Founded', 'HeadQuarter', 'Sector', 'What_it_does',\n",
      "       'Founders', 'Investor', 'Amount', 'Stage', 'column10'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print (data.columns )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data cleaning 1st Dataset-2020 (Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values \n",
    "\n",
    "# For columns with a few missing values, fill with 'Unknown'\n",
    "data['HeadQuarter'].fillna('Unknown', inplace=True)\n",
    "data['Sector'].fillna('Unknown', inplace=True)\n",
    "data['Founders'].fillna('Unknown', inplace=True)\n",
    "data['Investor'].fillna('Unknown', inplace=True)\n",
    " \n",
    "# For 'Founded', fill missing values with 0\n",
    "data['Founded'].fillna(data ['Founded']==0, inplace=True)\n",
    " \n",
    "# For 'Amount', fill missing values with the median funding amount\n",
    "data['Amount'].fillna(data['Amount'].median(), inplace=True)\n",
    " \n",
    "# For 'Stage', fill missing values with a placeholder\n",
    "data['Stage'].fillna('Unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Company_Brand       0\n",
       "Founded             0\n",
       "HeadQuarter         0\n",
       "Sector              0\n",
       "What_it_does        0\n",
       "Founders            0\n",
       "Investor            0\n",
       "Amount              0\n",
       "Stage               0\n",
       "column10         1053\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check to confirm there are no missing values \n",
    "\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Founded'  to integer datatype \n",
    "\n",
    "data['Founded'] = data ['Founded'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the stage column from object to category \n",
    "\n",
    "data['Stage'] = data['Stage'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the Column10 column it has more than 95% NULL values and also in the 2021,2019,2018 data this column is not available meaning its impact is minimal\n",
    "data.drop('column10', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates\n",
    "\n",
    "data.drop_duplicates( inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1052 entries, 0 to 1054\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count  Dtype   \n",
      "---  ------         --------------  -----   \n",
      " 0   Company_Brand  1052 non-null   object  \n",
      " 1   Founded        1052 non-null   int32   \n",
      " 2   HeadQuarter    1052 non-null   object  \n",
      " 3   Sector         1052 non-null   object  \n",
      " 4   What_it_does   1052 non-null   object  \n",
      " 5   Founders       1052 non-null   object  \n",
      " 6   Investor       1052 non-null   object  \n",
      " 7   Amount         1052 non-null   float64 \n",
      " 8   Stage          1052 non-null   category\n",
      "dtypes: category(1), float64(1), int32(1), object(6)\n",
      "memory usage: 72.3+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2nd Dataset-2021 (data2)\n",
    "\n",
    "* This dataset is loaded from SQL Database "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "DatabaseError",
     "evalue": "Execution failed on sql: SELECT * FROM dbo.LP1_startup_funding2021\n('08S01', '[08S01] [Microsoft][ODBC SQL Server Driver]Communication link failure (0) (SQLExecDirectW)')\nunable to rollback",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\sql.py:2672\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[1;34m(self, sql, params)\u001b[0m\n\u001b[0;32m   2671\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2672\u001b[0m     \u001b[43mcur\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2673\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cur\n",
      "\u001b[1;31mOperationalError\u001b[0m: ('08S01', '[08S01] [Microsoft][ODBC SQL Server Driver]Communication link failure (0) (SQLExecDirectW)')",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\sql.py:2676\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[1;34m(self, sql, params)\u001b[0m\n\u001b[0;32m   2675\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2676\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcon\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollback\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2677\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m inner_exc:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n",
      "\u001b[1;31mOperationalError\u001b[0m: ('08S01', '[08S01] [Microsoft][ODBC SQL Server Driver]Communication link failure (0) (SQLEndTran)')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Loading the second dataset which is our tabel 2 (Data2)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m query \u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'''\u001b[39m\u001b[38;5;124mSELECT * FROM dbo.LP1_startup_funding2021\u001b[39m\u001b[38;5;124m'''\u001b[39m\n\u001b[1;32m----> 4\u001b[0m data2 \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnection\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\sql.py:706\u001b[0m, in \u001b[0;36mread_sql\u001b[1;34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize, dtype_backend, dtype)\u001b[0m\n\u001b[0;32m    704\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pandasSQL_builder(con) \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pandas_sql, SQLiteDatabase):\n\u001b[1;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    707\u001b[0m \u001b[43m            \u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    708\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    709\u001b[0m \u001b[43m            \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    710\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoerce_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    711\u001b[0m \u001b[43m            \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    712\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    713\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    714\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    715\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    717\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    718\u001b[0m         _is_table_name \u001b[38;5;241m=\u001b[39m pandas_sql\u001b[38;5;241m.\u001b[39mhas_table(sql)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\sql.py:2736\u001b[0m, in \u001b[0;36mSQLiteDatabase.read_query\u001b[1;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[0;32m   2725\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_query\u001b[39m(\n\u001b[0;32m   2726\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   2727\u001b[0m     sql,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2734\u001b[0m     dtype_backend: DtypeBackend \u001b[38;5;241m|\u001b[39m Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2735\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Iterator[DataFrame]:\n\u001b[1;32m-> 2736\u001b[0m     cursor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2737\u001b[0m     columns \u001b[38;5;241m=\u001b[39m [col_desc[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m col_desc \u001b[38;5;129;01min\u001b[39;00m cursor\u001b[38;5;241m.\u001b[39mdescription]\n\u001b[0;32m   2739\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\sql.py:2681\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[1;34m(self, sql, params)\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m inner_exc:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[0;32m   2678\u001b[0m     ex \u001b[38;5;241m=\u001b[39m DatabaseError(\n\u001b[0;32m   2679\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecution failed on sql: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msql\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124munable to rollback\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2680\u001b[0m     )\n\u001b[1;32m-> 2681\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01minner_exc\u001b[39;00m\n\u001b[0;32m   2683\u001b[0m ex \u001b[38;5;241m=\u001b[39m DatabaseError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecution failed on sql \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msql\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2684\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[1;31mDatabaseError\u001b[0m: Execution failed on sql: SELECT * FROM dbo.LP1_startup_funding2021\n('08S01', '[08S01] [Microsoft][ODBC SQL Server Driver]Communication link failure (0) (SQLExecDirectW)')\nunable to rollback"
     ]
    }
   ],
   "source": [
    "#Loading the second dataset which is our tabel 2 (Data2)\n",
    "query ='''SELECT * FROM dbo.LP1_startup_funding2021'''\n",
    " \n",
    "data2 = pd.read_sql(query, connection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdata2\u001b[49m\u001b[38;5;241m.\u001b[39mhead ()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data2' is not defined"
     ]
    }
   ],
   "source": [
    "#data2.head ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data2.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data2.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning 2nd Dataset (data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify duplicates (excluding the first occurrence)\n",
    "duplicates = data2.duplicated(keep='first')\n",
    "\n",
    "# Compute the mode of each column\n",
    "mode_values = data2.mode().iloc[0]\n",
    "\n",
    "# Ensure that the mode values match the column names\n",
    "mode_dict = mode_values.to_dict()\n",
    "\n",
    "# Fill duplicates with the mode values\n",
    "data2.loc[duplicates, :] = data2.loc[duplicates, :].apply(lambda row: pd.Series(mode_dict), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check to see if the are duplicated values after filling with the mode values \n",
    "\n",
    "data2.duplicated().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the duplicates\n",
    "data2 = data2.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check to see if there are still remaining duplicates \n",
    "\n",
    "data2.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in our second data\n",
    "data2.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check to confirm there are no missing values     \n",
    "\n",
    "data2.isnull().sum()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting 'Amount' Column from string to numeric\n",
    "\n",
    "data2['Amount'] = pd.to_numeric(data2['Amount'], errors='coerce')\n",
    "\n",
    "# Check to confirm 'Amount Column is float\n",
    "data2['Amount'] = data2['Amount'].astype(float)\n",
    "\n",
    "print(data2['Amount'].dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3rd Dataset 2019 (df)\n",
    "\n",
    "* This Dataset is downloaded from a onedrive "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the one drive file which is the 2019 startups data (3rd Dataset)\n",
    "\n",
    "df=pd.read_excel ('C:\\\\Users\\\\Admin\\\\OneDrive\\\\OneDrive-Azubi\\\\CA-LP1\\\\LP1-Indian-Startup-Ecosystem-1\\\\startup_funding2019.xlsx')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data cleaning 3rd Dataset 2019- (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the Amount column to numeric values \n",
    "\n",
    "# Convert to numeric, coercing errors to NaN\n",
    "df['Amount($)'] = pd.to_numeric(df['Amount($)'], errors='coerce')\n",
    "\n",
    "# Check to confirm 'Amount Column is float\n",
    "df['Amount'] = data2['Amount'].astype(float)\n",
    "\n",
    "print(df['Amount'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in our Table 3 (df)\n",
    "df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to confirm there are no missing values\n",
    "df.isnull().sum() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4th Dataset 2018 (df2)\n",
    "\n",
    "* This dataset is from a GitHub repository. We had to clone from GitHub then copy csv file to our notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from GitHub repository \n",
    "\n",
    "df2=pd.read_csv('C:\\\\Users\\\\Admin\\\\OneDrive\\\\OneDrive-Azubi\\\\CA-LP1\\\\LP1-Indian-Startup-Ecosystem-1\\\\CA-LP1-Indian-Startup-Ecosystem-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.info ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.duplicated ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning our 4th Dataset (df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting our Amounts table from string to Float datatype \n",
    "\n",
    "df2['Amount'] =pd.to_numeric(df2['Amount'], errors='coerce')\n",
    "\n",
    "# Check to confirm 'Amount Column is float\n",
    "df2['Amount'] = data2['Amount'].astype(float)\n",
    "\n",
    "print(df2['Amount'].dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning of our data was done after each of the datasets. In this phase we concatenate our data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create standadized column names of data, data2, df and df2 \n",
    "\n",
    "# Step1 how our columns appear in each of the datasets\n",
    "\n",
    "data = pd.DataFrame(columns=['Company_Brand', 'Founded', 'HeadQuarter', 'Sector', 'What_it_does', 'Founders', 'Investor', 'Amount', 'Stage'])\n",
    "data2 = pd.DataFrame(columns=['Company_Brand', 'Founded', 'HeadQuarter', 'Sector', 'What_it_does', 'Founders', 'Investor', 'Amount', 'Stage'])\n",
    "df = pd.DataFrame(columns=['Company/Brand', 'Founded', 'HeadQuarter', 'Sector', 'What it does', 'Founders', 'Investor', 'Amount($)', 'Stage'])\n",
    "df2 = pd.DataFrame(columns=['Company Name', 'Industry', 'Round/Series', 'Amount', 'Location', 'About Company'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 Column maping\n",
    "\n",
    "# The standardized name column should be :\n",
    "\n",
    "'company_brand','founded','headquarter','sector','what_it_does','founders','investor','amount','stage'\n",
    "\n",
    "# Column mapping for `data` and `data2`\n",
    "mapping_data = {\n",
    "    'Company_Brand': 'company_brand',\n",
    "    'Founded': 'founded',\n",
    "    'HeadQuarter': 'headquarter',\n",
    "    'Sector': 'sector',\n",
    "    'What_it_does': 'what_it_does',\n",
    "    'Founders': 'founders',\n",
    "    'Investor': 'investor',\n",
    "    'Amount': 'amount',\n",
    "    'Stage': 'stage'\n",
    "}\n",
    "\n",
    "# Column mapping for `df`\n",
    "mapping_df = {\n",
    "    'Company/Brand': 'company_brand',\n",
    "    'Founded': 'founded',\n",
    "    'HeadQuarter': 'headquarter',\n",
    "    'Sector': 'sector',\n",
    "    'What it does': 'what_it_does',\n",
    "    'Founders': 'founders',\n",
    "    'Investor': 'investor',\n",
    "    'Amount($)': 'amount',\n",
    "    'Stage': 'stage'\n",
    "}\n",
    "\n",
    "# Column mapping for `df2`\n",
    "mapping_df2 = {\n",
    "    'Company Name': 'company_brand',\n",
    "    'Industry': 'sector',\n",
    "    'Round/Series': 'stage',\n",
    "    'Amount': 'amount',\n",
    "    'Location': 'headquarter',\n",
    "    'About Company': 'what_it_does'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3 Rename Columns \n",
    "\n",
    "# Rename columns\n",
    "data = data.rename(columns=mapping_data)\n",
    "data2 = data2.rename(columns=mapping_data)\n",
    "df = df.rename(columns=mapping_df)\n",
    "df2 = df2.rename(columns=mapping_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4 Ensure consistency \n",
    "\n",
    "# Ensure consistency by selecting only the standardized columns\n",
    "standardized_columns = ['company_brand', 'founded', 'headquarter', 'sector', 'what_it_does', 'founders', 'investor', 'amount', 'stage']\n",
    "\n",
    "# Reindex datasets to have only standardized columns and fill missing columns with NaN\n",
    "data = data.reindex(columns=standardized_columns)\n",
    "data2 = data2.reindex(columns=standardized_columns)\n",
    "df = df.reindex(columns=standardized_columns)\n",
    "df2 = df2.reindex(columns=standardized_columns)\n",
    "\n",
    "print(data.columns)\n",
    "print(data2.columns)\n",
    "print(df.columns)\n",
    "print(df2.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge all the 4 datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_merge = pd.concat([data, data2, df, df2], ignore_index=True)\n",
    "\n",
    "#df_merge.head()\n",
    "\n",
    "print (\"\\nMerged DataFrame: \")\n",
    "print (df_merge.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
